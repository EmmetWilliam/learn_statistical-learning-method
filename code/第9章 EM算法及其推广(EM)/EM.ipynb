{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第9章 EM算法及其推广\n",
    "\n",
    "配置环境：python 3.6\n",
    "\n",
    "代码全部测试通过。\n",
    "\n",
    "代码参考 : https://github.com/Dod-o/Statistical-Learning-Method_Code/blob/master/EM/EM.py\n",
    "\n",
    "此文档方便阅读，若需要复制粘贴可以在当前目录中查看`EM.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_data(mu0, sigma0, mu1, sigma1, alpha0, alpha1):\n",
    "    '''\n",
    "    初始化数据集\n",
    "    这里通过服从高斯分布的随机函数来伪造数据集\n",
    "    :param mu0: 高斯0的均值\n",
    "    :param sigma0: 高斯0的方差\n",
    "    :param mu1: 高斯1的均值\n",
    "    :param sigma1: 高斯1的方差\n",
    "    :param alpha0: 高斯0的系数\n",
    "    :param alpha1: 高斯1的系数\n",
    "    :return: 混合了两个高斯分布的数据\n",
    "    '''\n",
    "    #定义数据集长度为1000\n",
    "    length = 1000\n",
    "    \n",
    "    #初始化第一个高斯分布，生成数据，数据长度为length * alpha系数，以此来\n",
    "    #满足alpha的作用\n",
    "    data0 = np.random.normal(mu0, sigma0, int(length * alpha0))\n",
    "    #第二个高斯分布的数据\n",
    "    data1 = np.random.normal(mu1, sigma1, int(length * alpha1))\n",
    "\n",
    "    #初始化总数据集\n",
    "    #两个高斯分布的数据混合后会放在该数据集中返回\n",
    "    dataSet = []\n",
    "    #将第一个数据集的内容添加进去\n",
    "    dataSet.extend(data0)\n",
    "    #添加第二个数据集的数据\n",
    "    dataSet.extend(data1)\n",
    "\n",
    "    #返回伪造好的数据集\n",
    "    return dataSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载自己伪造的高斯数据\n",
    "# 假设伪造的数据只有两个高斯混合\n",
    "# mu0 sigma0 alpha0 是第一个高斯\n",
    "# mu1 sigma1 alpha1 是第二个高斯\n",
    "# alpha0 alpha1 是比例系数 相加为 1\n",
    "mu0, sigma0, alpha0 = -2.0, 0.5, 0.3\n",
    "mu1, sigma1, alpha1 = 0.5, 1.0, 0.7 \n",
    "data = create_data(mu0, sigma0, mu1, sigma1, alpha0, alpha1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_gauss(dataSetArr, mu, sigmod):\n",
    "    '''\n",
    "    根据高斯密度函数计算值\n",
    "    依据：“9.3.1 高斯混合模型” 式9.25\n",
    "    注：在公式中y是一个实数，但是在EM算法中(见算法9.2的E步)，需要对每个j\n",
    "    都求一次yjk，在本实例中有1000个可观测数据，因此需要计算1000次。考虑到\n",
    "    在E步时进行1000次高斯计算，程序上比较不简洁，因此这里的y是向量，在numpy\n",
    "    的exp中如果exp内部值为向量，则对向量中每个值进行exp，输出仍是向量的形式。\n",
    "    所以使用向量的形式1次计算即可将所有计算结果得出，程序上较为简洁\n",
    "    :param dataSetArr: 可观测数据集\n",
    "    :param mu: 均值\n",
    "    :param sigmod: 方差\n",
    "    :return: 整个可观测数据集的高斯分布密度（向量形式）\n",
    "    '''\n",
    "    #计算过程就是依据式9.25写的，没有别的花样\n",
    "    result = (1 / (math.sqrt(2 * math.pi) * sigmod**2)) * \\\n",
    "        np.exp(-1 * (dataSetArr - mu) * (dataSetArr - mu) / (2 * sigmod**2))\n",
    "    #返回结果\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array(data).reshape(1, len(data))\n",
    "cal_gauss(test_data, 0.1, 0.1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EM_Gauss:\n",
    "    def load_data(self, data):\n",
    "        # 保存所有数据，转换成 np.array\n",
    "        self.data = np.array(data).reshape(1, len(data))\n",
    "\n",
    "    def init_args(self, all_args):\n",
    "        # 保存所有参数\n",
    "        self.all_args = all_args\n",
    "        # 模型数目\n",
    "        self.K = len(all_args) // 3\n",
    "        # 样本长度\n",
    "        _, self.N = self.data.shape\n",
    "\n",
    "    # E 步骤\n",
    "    def E(self):\n",
    "        # 用来保存中间值\n",
    "        t_d = {}\n",
    "        # 保存分母\n",
    "        _sum = np.zeros((1, self.N))\n",
    "        # print('_sum', _sum.shape)\n",
    "        for k in range(self.K):\n",
    "            str_k = str(k)\n",
    "            key = 'gauss' + str_k\n",
    "            # 计算所有的 y 的高斯值\n",
    "            # 只需将第 k 个的均值和方差传入就行\n",
    "            # 计算 算法 9.2 (2) 的分子\n",
    "            t_d[key] = cal_gauss(self.data, self.all_args[\"mu\"+str_k], self.all_args['sigma'+str_k])\n",
    "            t_d[key] = self.all_args[\"alpha\"+str_k] * t_d[key]\n",
    "            # 计算分母, 这是两个同等长度的 np.array() 相加，等价于对应元素相加\n",
    "            _sum += t_d[key]\n",
    "\n",
    "        all_gamma = {}\n",
    "        for k in range(self.K):\n",
    "            # 计算 k 层的所有 gamma\n",
    "            str_k = str(k)\n",
    "            key1 = 'gamma' + str_k\n",
    "            key2 = 'gauss' + str_k\n",
    "            all_gamma[key1] = t_d[key2] / _sum\n",
    "        \n",
    "        return all_gamma\n",
    "\n",
    "\n",
    "    # 步骤 M 更新参数\n",
    "    def M(self, all_gamma):\n",
    "        \"\"\"\n",
    "        更新模型参数\n",
    "        \"\"\"\n",
    "        # 书上公式 算法 9.2 (3)\n",
    "        for k in range(self.K):\n",
    "            str_k = str(k)\n",
    "            sum_gamma = np.sum(all_gamma['gamma'+str_k])\n",
    "            \n",
    "            self.all_args['mu'+str_k] = np.sum(all_gamma['gamma'+str_k] * self.data) / sum_gamma\n",
    "            self.all_args['sigma'+str_k] = np.sqrt(\n",
    "                np.sum(all_gamma['gamma'+str_k] * np.square(self.data - self.all_args['mu'+str_k])) / sum_gamma\n",
    "            )\n",
    "            self.all_args['alpha' + str_k] = sum_gamma / self.N\n",
    "\n",
    "\n",
    "    def train(self, max_iters=100):\n",
    "        for t in range(max_iters):\n",
    "            # 计算 E 步骤\n",
    "            all_gamma = self.E()\n",
    "            # 计算 M 步骤\n",
    "            self.M(all_gamma)\n",
    "        \n",
    "        print('train done!')\n",
    "        return self.all_args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train done!\n",
      "{'mu0': -1.7595668808581895, 'sigma0': 0.6619882505787064, 'alpha0': 0.37782012864442904, 'mu1': 0.7111745770268607, 'sigma1': 0.8562346740076474, 'alpha1': 0.622179871355571}\n",
      "{'mu0': -2.0, 'sigma0': 0.5, 'alpha0': 0.3, 'mu1': 0.5, 'sigma1': 1.0, 'alpha1': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# 创建 EM_Gauss 类\n",
    "em = EM_Gauss()\n",
    "# 加载数据\n",
    "em.load_data(data)\n",
    "# 初始化参数\n",
    "# 在 M 步中有三个参数要更新\n",
    "# 现在定义每个参数的初始值\n",
    "\n",
    "raw_args = {\n",
    "    'mu0': mu0,\n",
    "    'sigma0': sigma0,\n",
    "    'alpha0': alpha0,\n",
    "    'mu1': mu1,\n",
    "    'sigma1': sigma1, \n",
    "    'alpha1': alpha1\n",
    "}\n",
    "\n",
    "all_args = {\n",
    "    'mu0': 0.,\n",
    "    'sigma0': 1.0,\n",
    "    'alpha0': 0.5,\n",
    "    'mu1': 1.0,\n",
    "    'sigma1': 1.0,\n",
    "    'alpha1': 0.5 \n",
    "}\n",
    "em.init_args(all_args)\n",
    "all_args = em.train(max_iters=500)\n",
    "\n",
    "print(all_args)\n",
    "\n",
    "print(raw_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
