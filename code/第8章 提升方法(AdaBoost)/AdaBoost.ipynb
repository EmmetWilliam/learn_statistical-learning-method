{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第8章 提升方法\n",
    "\n",
    "配置环境：python 3.6\n",
    "\n",
    "代码全部测试通过。\n",
    "\n",
    "代码参考 : https://github.com/wzyonggege/statistical-learning-method/blob/master/AdaBoost/Adaboost.ipynb\n",
    "\n",
    "此文档方便阅读，若需要复制粘贴可以在当前目录中查看`AdaBoost.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成数据\n",
    "def create_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = ['sepal length', 'sepal width',\n",
    "                  'petal length', 'petal width', 'label']\n",
    "    data = np.array(df.iloc[:100, [0, 1, -1]])\n",
    "    for i in range(len(data)):\n",
    "        if data[i, -1] == 0:\n",
    "            data[i, -1] = -1\n",
    "    return data[:, :2], data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f62cef72a90>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = create_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "plt.scatter(X[:50, 0], X[:50, 1], label='0')\n",
    "plt.scatter(X[50:, 0], X[50:, 1], label='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost():\n",
    "    def __init__(self, cls_num=100, lr=0.1):\n",
    "        self.cls_num = cls_num\n",
    "        self.lr = lr\n",
    "    \n",
    "    def load_data(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def init_args(self):\n",
    "        self.sample_num, self.feature_num = self.X.shape\n",
    "        self.alpha = [0] * self.cls_num\n",
    "        # 初始化权重 书上公式 算法 8.1 (1)\n",
    "        self.w = [1.0 / self.sample_num] * self.sample_num\n",
    "        # self.clf_sets[]\n",
    "        # 保存每一层的参数，(axis, v, direct)\n",
    "        # axis 是哪个特征比如 x0\n",
    "        # v 是阈值\n",
    "        # direct 在后面解释\n",
    "        self.clf_sets = []\n",
    "\n",
    "    def cal_error(self, x):\n",
    "        \"\"\"\n",
    "        计算分类误差率，并选取最合适的阈值\n",
    "\n",
    "        其中我们选择了阈值 v,但是不确定的是比阈值大的时候取 1 还是阈值小的时候取 1 \n",
    "        所以规定 direct 记录方向\n",
    "        \"\"\"\n",
    "        error, direct, g_array, best_v = float('inf'), '', None, 0.0\n",
    "        _min = min(x)\n",
    "        _max = max(x)\n",
    "        n_step = (_max - _min + self.lr) // self.lr\n",
    "\n",
    "        # 选取阈值\n",
    "        t_direct, t_error, t_array = None, None, None\n",
    "        for i in range(1, int(n_step)):\n",
    "            v = _min + i * self.lr\n",
    "            # 保证阈值不在 x 内\n",
    "            if v not in x:\n",
    "                # 生成比阈值大为 1 的预测数组\n",
    "                postive_array = [1 if x[k] > v else -1 for k in range(self.sample_num)]\n",
    "                # 计算误差\n",
    "                postive_error = sum([self.w[k] for k in range(self.sample_num) if postive_array[k] != self.y[k]])\n",
    "                \n",
    "                # 生成比阈值小为 -1 的预测数组\n",
    "                nagative_array = [-1 if x[k] > v else 1 for k in range(self.sample_num)]\n",
    "                nagative_error = sum([self.w[k] for k in range(self.sample_num) if nagative_array[k] != self.y[k]])\n",
    "                \n",
    "                # 比较谁的分类效果好\n",
    "                if postive_error < nagative_error:\n",
    "                    t_direct = 'postive'\n",
    "                    t_error = postive_error\n",
    "                    t_array = postive_array\n",
    "                else:\n",
    "                    t_direct = 'negative'\n",
    "                    t_error = nagative_error\n",
    "                    t_array = nagative_array\n",
    "                # 如果当前误差小于已保存的误差\n",
    "                # 则更新误差\n",
    "                if error > t_error:\n",
    "                    error, direct, g_array, best_v = t_error, t_direct, t_array, v\n",
    "        # 返回误差，方向，预测数组，阈值\n",
    "        return error, direct, g_array, best_v\n",
    "                    \n",
    "\n",
    "\n",
    "    # 计算 alpha\n",
    "    def cal_alpha(self, idx, error):\n",
    "        \"\"\"\n",
    "        书上公式 8.2\n",
    "        \"\"\"\n",
    "        self.alpha[idx] = (1/2)*math.log((1-error) / error)\n",
    "\n",
    "    # 计算 Z\n",
    "    def cal_Z(self, alpha, g_array):\n",
    "        \"\"\"\n",
    "        书上公式 8.5\n",
    "        \"\"\"\n",
    "        Z = 0.0\n",
    "        for i in range(self.sample_num):\n",
    "            exp = math.exp(-alpha * self.y[i] * g_array[i])\n",
    "            Z += self.w[i] * exp\n",
    "\n",
    "        return Z\n",
    "\n",
    "    # 更新权值\n",
    "    def update_w(self, alpha, Z, g_array):\n",
    "        \"\"\"\n",
    "        书上公式 140 最上面\n",
    "        \"\"\"\n",
    "        for i in range(self.sample_num):\n",
    "            if g_array[i] == self.y[i]:\n",
    "                self.w[i] = (self.w[i] / Z) * math.exp(-alpha)\n",
    "            else:\n",
    "                self.w[i] = (self.w[i] / Z) * math.exp(alpha)\n",
    "\n",
    "    # 根据每一层的参数，返回预测类别\n",
    "    def G(self, x, v, direct):\n",
    "        if direct == 'positive':\n",
    "            return 1 if x > v else -1 \n",
    "        else:\n",
    "            return -1 if x > v else 1 \n",
    "    \n",
    "    # 训练\n",
    "    def fit(self):\n",
    "        \n",
    "        for epoch in range(self.cls_num):\n",
    "            direct = 'positive'\n",
    "            axis = 0\n",
    "            min_error, best_v, g_array = float('inf'), 0, None\n",
    "            # 遍历所有特征，从所有的特征中找到阈值\n",
    "            for j in range(self.feature_num):\n",
    "                x = self.X[:, j]\n",
    "                # 寻找当前特征最好的阈值，以及最小的误差\n",
    "                error, temp_direct, temp_g_array, v = self.cal_error(x)\n",
    "                # 如果当前特征的误差小于已保存的误差\n",
    "                # 则更新误差\n",
    "                if error < min_error:\n",
    "                    best_v = v\n",
    "                    g_array = temp_g_array\n",
    "                    direct = temp_direct\n",
    "                    min_error = error\n",
    "                    axis = j\n",
    "                # 如果误差为 0 不用继续下去了\n",
    "                if min_error == 0:\n",
    "                    break\n",
    "            # 计算 alpha 书上公式 8.2   \n",
    "            self.cal_alpha(epoch, error)\n",
    "            # 计算 Z 书上公式 8.5\n",
    "            Z = self.cal_Z(self.alpha[epoch], g_array)\n",
    "            # 添加进弱分类器的数组集合\n",
    "            self.clf_sets.append((axis, best_v, direct))\n",
    "            # 更新 权重\n",
    "            self.update_w(self.alpha[epoch], Z, g_array)\n",
    "\n",
    "    def predict(self, feature):\n",
    "        result = 0.0\n",
    "        for i in range(len(self.clf_sets)):\n",
    "            axis, clf_v, direct = self.clf_sets[i]\n",
    "            f_input = feature[axis]\n",
    "            result += self.alpha[i] * self.G(f_input, clf_v, direct)\n",
    "        return 1 if result > 0 else -1\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        right_count = 0\n",
    "        for i in range(len(X_test)):\n",
    "            feature = X_test[i]\n",
    "            if self.predict(feature) == y_test[i]:\n",
    "                right_count += 1\n",
    "\n",
    "        return right_count / len(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.7466666666666667\n"
     ]
    }
   ],
   "source": [
    "ab = AdaBoost()\n",
    "ab.load_data(X_train, y_train)\n",
    "ab.init_args()\n",
    "ab.fit()\n",
    "\n",
    "print('score', ab.score(X_train, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
