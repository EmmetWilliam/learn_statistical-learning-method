{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第5章 决策树\n",
    "\n",
    "配置环境：python 3.6\n",
    "\n",
    "代码全部测试通过。\n",
    "\n",
    "此文档方便阅读讲解，若需要复制粘贴可以在当前目录中查看`DecisionTree.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNode:\n",
    "    def __init__(self, root=None, feature_name=None, label=None):\n",
    "        \"\"\"\n",
    "        :param root root=False 是分类节点 root=True 是叶节点\n",
    "        :param feature_name feature_name 表示分类节点的分类名字\n",
    "        :param label 根节点的类别，如果还有类别不唯一，通常是分类到最后，最多的那个类别，如果不是叶节点\n",
    "        label 为 None\n",
    "        \"\"\"\n",
    "        \n",
    "        self.root = root\n",
    "        self.feature_name = feature_name\n",
    "        self.label = label\n",
    "        self.tree = {}\n",
    "        self.result = {'label': self.label, 'feature_name': self.feature_name, 'tree': self.tree}\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        输出这个对象的时候调用这个函数\n",
    "        \"\"\"\n",
    "        return '{}'.format(self.result)\n",
    "\n",
    "    def add_node(self, val, node):\n",
    "        \"\"\"\n",
    "        添加子节点\n",
    "        \"\"\"\n",
    "        self.tree[val] = node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTree:\n",
    "    def __init__(self, epsilon=0.1):\n",
    "        \"\"\"\n",
    "        epsilon 信息增益的阈值\n",
    "        如果最大信息增益小于阈值，就不继续分节点了\n",
    "        \"\"\"\n",
    "        self._tree = None\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    @staticmethod\n",
    "    def cal_ent(dataset):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        data_length = len(dataset)\n",
    "        labels = {}\n",
    "        for i in range(data_length):\n",
    "            label = dataset[i][-1]\n",
    "            if label not in labels:\n",
    "                labels[label] = 0\n",
    "            labels[label] += 1\n",
    "        ent = -sum([(p/data_length)*log(p/data_length, 2) \n",
    "                for p in labels.values()])\n",
    "        print('ent', ent)\n",
    "        \n",
    "        return ent\n",
    "\n",
    "    def cond_ent(self, dataset, axis=0):\n",
    "        # 计算经验条件熵\n",
    "        data_length = len(dataset)\n",
    "        cla_via_feature = {}\n",
    "        for r in range(data_length):\n",
    "            f = dataset[r][axis]\n",
    "            if f not in cla_via_feature:\n",
    "                cla_via_feature[f] = []\n",
    "            cla_via_feature[f].append(dataset[r])\n",
    "        ent = sum([(len(p)/data_length)*self.cal_ent(p) \n",
    "                    for p in cla_via_feature.values()])\n",
    "        return ent\n",
    "\n",
    "    def info_gain(self, ent, c_ent):\n",
    "        return ent - c_ent\n",
    "\n",
    "    def info_gain_train(self, dataset):\n",
    "        count = len(dataset[0]) - 1\n",
    "        # 计算熵\n",
    "        ent = self.cal_ent(dataset)\n",
    "        best_feature = []\n",
    "        for c in range(count):\n",
    "            c_info_gain = self.info_gain(ent, self.cond_ent(dataset, axis=c))\n",
    "            best_feature.append((c, c_info_gain))\n",
    "        best_ = max(best_feature, key=lambda x: x[-1])\n",
    "\n",
    "        return best_\n",
    "\n",
    "    def train(self, train_data):\n",
    "        \"\"\"\n",
    "        递归函数\n",
    "        1. 先得到数据\n",
    "            数据格式是 pandas\n",
    "        2. 判断是否是单节点树\n",
    "            1. 所有分类的样本的标签是一样的\n",
    "            2. 虽然有的标签不一样，但是特征值用完了，现在强行弄成标签一样，类别最多的那个\n",
    "        3. 计算经验熵和条件经验熵，计算信息增益，算出信息增益最大的那个\n",
    "            1. 如果最大信息增益小于阈值，强行弄成标签一样，类别最多的那个\n",
    "        4. 把由 3 产生的数据重复执行前三步\n",
    "        \"\"\" \n",
    "        y_train, features = train_data.iloc[:, -1], train_data.columns[:-1]\n",
    "        \n",
    "        # 如果是都是一样的类，返回单节点树\n",
    "        if len(y_train.value_counts()) == 1:\n",
    "            return DNode(root=True, label=y_train.iloc[0])\n",
    "        \n",
    "        # 没有可分的特征值了，返回单节点树\n",
    "        if len(features) == 0:\n",
    "            return DNode(root=True, \n",
    "                        label=y_train.value_counts().sort_value(ascending=False).index[0])\n",
    "        \n",
    "        # 计算经验熵和经验条件熵\n",
    "        max_feature, max_info_gain = self.info_gain_train(np.array(train_data))\n",
    "        max_feature_name = features[max_feature]\n",
    "        print('max_feature max_feature_name', max_feature, max_feature_name)\n",
    "\n",
    "        if max_info_gain < self.epsilon:\n",
    "            return DNode(root=True,\n",
    "                        label=y_train.value_counts().sort_value(ascending=False).index[0])\n",
    "\n",
    "        # 构建子集\n",
    "        node_tree = DNode(root=False, \n",
    "                        feature_name=max_feature_name)\n",
    "\n",
    "        # 将那些数据按 max_feature_name 分开\n",
    "        feature_list = train_data[max_feature_name].value_counts().index\n",
    "\n",
    "        for f in feature_list:\n",
    "            sub_train_df = train_data.loc[train_data[max_feature_name] == f].drop(\n",
    "                [max_feature_name], axis=1)\n",
    "\n",
    "            sub_tree = self.train(sub_train_df)\n",
    "            node_tree.add_node(f, sub_tree)\n",
    "\n",
    "        return node_tree\n",
    "\n",
    "    def fit(self, train_data):\n",
    "        self._tree = self.train(train_data)\n",
    "        return self._tree\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
